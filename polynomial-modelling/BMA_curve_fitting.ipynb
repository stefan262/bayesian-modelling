{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BMA_curve_fitting.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "TzD0o2kEk3Lg",
        "m3pdF9nVk3zr"
      ],
      "authorship_tag": "ABX9TyOoJXImGmEItThuP1+ADv53"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzD0o2kEk3Lg"
      },
      "source": [
        "## import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17CA6_Xj8kH7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96919d11-af39-44c9-f968-f9a0fdcd0e54"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.optimize\n",
        "import scipy.stats\n",
        "import math\n",
        "import random\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "from statsmodels.regression.linear_model import OLS\n",
        "from statsmodels.tools import add_constant\n",
        "from sklearn.model_selection import train_test_split\n",
        "from itertools import combinations\n",
        "\n",
        "from mpmath import mp\n",
        "mp.dps = 50"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3pdF9nVk3zr"
      },
      "source": [
        "## class Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kGyUUpKrQvF"
      },
      "source": [
        "class Model:\n",
        "  \n",
        "  def __init__(self,x_i,y_i,allowed_polynomials):\n",
        "    ''' class representing a simple polynomial regression model\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    x: 1d numpy.array\n",
        "        feature vector\n",
        "    y: 1d numpy.array\n",
        "        response vector\n",
        "    allowed_polynomials: 1d list\n",
        "        allowed degrees for polynomials of the feature vector\n",
        "    '''\n",
        "\n",
        "    self.x = x_i\n",
        "    self.y = y_i\n",
        "    self.allowed_polynomials = allowed_polynomials\n",
        "    self.n_param = len(allowed_polynomials)\n",
        "    self.likl=0\n",
        "    self.params = []\n",
        "\n",
        "    \n",
        "  def fit(self):\n",
        "    ''' fits the polynomial regression using ordinary least squares (OLS) from statsmodels.regression.linear_model \n",
        "    '''\n",
        "\n",
        "    model_features = np.column_stack([self.x**i for i in self.allowed_polynomials])\n",
        "    model_regr = OLS(self.y, model_features).fit()\n",
        "    self.likl = mp.exp(-model_regr.bic/2)\n",
        "    self.params = model_regr.params\n",
        "    \n",
        "    return self\n",
        "  \n",
        "  def is_subModel(self,other):\n",
        "    ''' check if a model is a subModel of another one\n",
        "    Parameters\n",
        "    ----------\n",
        "    other: Model\n",
        "        the other model that will be checked against\n",
        "    Returns\n",
        "    -------\n",
        "    True or False\n",
        "    '''\n",
        "\n",
        "    if len(self.allowed_polynomials) >= len(other.allowed_polynomials):\n",
        "      return False\n",
        "    else:\n",
        "      for i in range(0,len(self.allowed_polynomials)):\n",
        "        if not self.allowed_polynomials[i] in other.allowed_polynomials:\n",
        "          return False\n",
        "      return True\n",
        "  \n",
        "  def predict(self,x_i):\n",
        "\n",
        "    y_pred = np.zeros(len(x_i))\n",
        "    for i in range(0,len(x_i)):\n",
        "      for j in range(0, len(self.allowed_polynomials)):\n",
        "        y_pred[i]+= self.params[j] * np.power(x_i[i],self.allowed_polynomials[j])\n",
        "    \n",
        "    return y_pred\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2BHNnof-97w"
      },
      "source": [
        "## class BMA_poly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiDl13ZD-9Xr"
      },
      "source": [
        "class BMA_poly:\n",
        "  \n",
        "  def __init__(self,x_i,y_i,max_degree,c_cutoff):\n",
        "    '''class repressenting Byaesian model averaging for polynomial curve fitting using the method known as \"Occam's window\". This implementation of Occam's window \n",
        "    rejects models that are 1/c_cutoff less likely than the most likely model, and rejects new complex models that are less likely than one of their submodels. \n",
        "    The priors are assumed to be uniform for this problem.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    x: 1d numpy.array\n",
        "        features vector\n",
        "    y: 1d numpy.array\n",
        "        response vector\n",
        "    max_degree: float\n",
        "        maximum degree for the polynomial regression (i.e. for max_degree = 10 we can have a polynomial of up to x^10)\n",
        "    c_cutoff: float\n",
        "        some models will be discarded if they predict the data far less well (i.e. if max_lik/lik_A > c_cutoff then model A will be discarded)\n",
        "    \n",
        "    '''\n",
        "\n",
        "    self.x = x_i\n",
        "    self.y = y_i\n",
        "    self.max_degree = max_degree\n",
        "    self.c_cutoff = c_cutoff\n",
        "    self.good_models=[]\n",
        "    self.sum_likl = 0\n",
        "\n",
        "  \n",
        "  def occam_razor(self, curr_model):\n",
        "    '''excludes complex models which receive less support from the data than their simpler counterparts.\n",
        "    Given the list of good_models is always ordered by the number of parameters all subModels will already be included and checked\n",
        "    Parameters\n",
        "    ----------\n",
        "    model: Model\n",
        "        model that needs to be checked\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    False if the model is too complex and True if the model is good and can be included\n",
        "    '''\n",
        "    for a_model in self.good_models:\n",
        "      if a_model.is_subModel(curr_model) and a_model.likl > curr_model.likl:\n",
        "        return False\n",
        "\n",
        "    return True \n",
        "\n",
        "  def fit(self):\n",
        "    '''perform the Bayesian model averaging \n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    self: BMA_poly\n",
        "        Returns the new BMA_poly object as an output\n",
        "    '''\n",
        "     \n",
        "    max_likl = 0\n",
        "    \n",
        "    # iterate through all possible models by going through the number of parameters (i.e. polynomial degrees)\n",
        "    for num_parameters in range(1,self.max_degree+1): \n",
        "\n",
        "      # list of all models with fixed num_parameters (it will be a list of numbers that represent the allowed polynomial degrees from 0->20)\n",
        "      current_list = list(combinations(list(range(self.max_degree)), num_parameters))\n",
        "\n",
        "      for allowed_polynomials in current_list:\n",
        "        curr_model = Model(self.x,self.y,allowed_polynomials).fit()\n",
        "        \n",
        "        # decide whether to save this model or not by first comparing its likl with the max_likl and then checking if there are any better subModels\n",
        "        if max_likl/curr_model.likl < self.c_cutoff and self.occam_razor(curr_model):\n",
        "          self.good_models.append(curr_model)\n",
        "\n",
        "          # update the max_likl if needed and update the list of good models\n",
        "          if curr_model.likl > max_likl:\n",
        "            max_likl = curr_model.likl\n",
        "            for a_model in self.good_models:\n",
        "              if max_likl/a_model.likl > self.c_cutoff:\n",
        "                self.good_models.remove(a_model)\n",
        " \n",
        "    self.sum_likl = 0\n",
        "    for a_model in self.good_models:\n",
        "      self.sum_likl += a_model.likl\n",
        "      \n",
        "    # Return the new BMA object as an output.\n",
        "    return self\n",
        "  \n",
        "  def predict(self, x_i):\n",
        "\n",
        "    y_pred = np.zeros(len(x_i))\n",
        "    for a_model in self.good_models:\n",
        "      prob = a_model.likl/self.sum_likl\n",
        "      for i in range(0,len(x_i)):\n",
        "        y_pred[i] +=  prob * a_model.predict(x_i)[i]\n",
        "\n",
        "    return y_pred\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gVfqQm1_EQB"
      },
      "source": [
        "## tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsGV3cQvOKxf"
      },
      "source": [
        "# generate random data\n",
        "num_poly = 8 # number of polyomials\n",
        "num_data = 200 # number of data points\n",
        "\n",
        "weights = [np.random.uniform(-1,1) for i in range(0,num_poly)]\n",
        "def f(x,weights):\n",
        "    y = np.random.uniform(0,1)\n",
        "    for i in range(0,len(weights)):\n",
        "        y += weights[i]*np.power(x,i)\n",
        "    return y\n",
        "\n",
        "# generate some input data and add noise\n",
        "input_data = [(lambda x:(x,f(x,weights)))(np.random.uniform(-5,5)) for i in range(0,num_data)]\n",
        "\n",
        "x_data, y_data = [[ i for i, j in input_data ],[ j for i, j in input_data ]] #unzip the tuples in input_data\n",
        "x_train = np.array(x_data)[:int(num_data/2)]\n",
        "y_train = np.array(y_data)[:int(num_data/2)]\n",
        "x_test = np.array(x_data)[int(num_data/2):]\n",
        "y_test = np.array(y_data)[int(num_data/2):]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhnyPZW9NjvP"
      },
      "source": [
        "def train(x_ii, y_ii, x_to_test):\n",
        "  result_BMA = BMA_poly(x_ii, y_ii, 10, 20).fit()\n",
        "  result_MAP = result_BMA.good_models[0]\n",
        "  max_likl = 0\n",
        "  for a_model in result_BMA.good_models:\n",
        "    if a_model.likl > max_likl:\n",
        "      max_likl = a_model.likl\n",
        "      result_MAP = a_model\n",
        "  \n",
        "  y_pred_BMA = result_BMA.predict(x_to_test)\n",
        "  y_pred_MAP = result_MAP.predict(x_to_test)\n",
        "\n",
        "  print(\"BMA gives models:\")\n",
        "  for i in range(0,len(result.good_models)):\n",
        "    print(result.good_models[i].allowed_polynomials, \"with probability of \" + str(result.good_models[i].likl/result.sum_likl))\n",
        "\n",
        "  print(\"\\n\")\n",
        "  return y_pred_BMA, y_pred_MAP"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUhRaCpstIeM",
        "outputId": "4fb2a17d-2108-402e-a814-e552ed455743"
      },
      "source": [
        "# compare BMA_poly with the MAP method which only chooses the best among all models\n",
        "\n",
        "y_1, y_2 = train(x_train, y_train, x_test)\n",
        "\n",
        "print(\"BMA gives an rmse of:\"+str(np.sqrt(sum((y_1 - y_test)**2)/len(y_test))))\n",
        "print(\"MAP gives an rmse of:\"+str(np.sqrt(sum((y_2 - y_test)**2)/len(y_test))))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BMA gives models:\n",
            "(0, 1, 2, 3, 4, 5, 6, 7) with probability of 0.4030336661373285908062383521295004707988498575133\n",
            "(0, 1, 2, 3, 4, 5, 6, 7, 8) with probability of 0.5969663338626714091937616478704995292011501424867\n",
            "\n",
            "\n",
            "BMA gives an rmse of:0.3096121982859752\n",
            "MAP gives an rmse of:0.3179593274264541\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbvSgYo3QZU2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
